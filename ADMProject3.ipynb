{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import pairwise_distances as pwd\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "\n",
    "def uMat(df, shape):\n",
    "    'Utility Matrix'\n",
    "    uMat = np.zeros(shape)\n",
    "    for line in df.itertuples(index = False):\n",
    "        uMat[line[3]-1,line[4]-1] = line[2]\n",
    "    return uMat\n",
    "\n",
    "def sim(mat):\n",
    "    'Similarity Matrix'\n",
    "    sim = 1-pwd(mat, metric = 'cosine')\n",
    "    eps = np.finfo(float).eps\n",
    "    sim[sim <= 0] = eps\n",
    "    return sim\n",
    "\n",
    "def isn(mat):\n",
    "    '''Number of nan values'''\n",
    "    return np.isnan(mat).sum()\n",
    "\n",
    "\n",
    "def ztn(mat):\n",
    "    '''Zero to nan'''\n",
    "    mat[mat == 0] = np.nan\n",
    "    return mat\n",
    "\n",
    "def ntz(mat):\n",
    "    '''Nan to zero'''\n",
    "    mat = np.nan_to_num(mat)\n",
    "    return mat\n",
    "\n",
    "def nmean(mat, axis = None):\n",
    "    '''Return mean considering only elements differents from zero.\n",
    "    Transform nan values to zero.'''\n",
    "    m = np.true_divide(mat.sum(axis), (mat != 0).sum(axis))\n",
    "    return ntz(m)\n",
    "\n",
    "def normU(uMat):\n",
    "    '''Normalize the utility matrix with the base rating.\n",
    "    The base ratings is obtained as OverallMean+(UserMean - OverallMean)+\n",
    "    +(ItemMean - OverallMean)'''\n",
    "    mat = uMat.copy()\n",
    "    OverallMean = ntz(nmean(mat))\n",
    "    ItemMean = ntz(nmean(mat, 0))\n",
    "    UserMean = ntz(nmean(mat, 1))\n",
    "    baseR = UserMean[:,np.newaxis] + ItemMean[np.newaxis,:] - OverallMean \n",
    "    mat = ztn(mat)\n",
    "    normMat = mat  - baseR\n",
    "    mat = ntz(mat)\n",
    "    normMat = ntz(normMat)\n",
    "    return normMat, baseR\n",
    "\n",
    "\n",
    "def pred(input_mat, cf_mode = 'u'):\n",
    "    mat = input_mat.copy()\n",
    "    Norm, baseR = normU(mat)\n",
    "    \n",
    "    if cf_mode == 'u':\n",
    "        Usim = sim(Norm)\n",
    "        Usimsim = (np.abs(Usim).sum(1))[:, np.newaxis]\n",
    "        Upred = baseR + Usim.dot(Norm)/Usimsim\n",
    "        return {'pred':Upred, 'sim':Usim}\n",
    "    \n",
    "    if cf_mode == 'i':\n",
    "        Isim = sim(Norm.T)\n",
    "        Isimsim = (np.abs(Isim).sum(1))[:, np.newaxis]\n",
    "        Ipred = baseR.T + Isim.dot(mat.T)/Isimsim\n",
    "        return {'pred':Ipred.T, 'sim':Isim}\n",
    "    \n",
    "def rmse(pred, truth):\n",
    "    '''Compute the root mean squared error.\n",
    "    '''\n",
    "    xHat = pred[truth.nonzero()].flatten()\n",
    "    x = truth[truth.nonzero()].flatten()\n",
    "    return np.sqrt(mse(xHat,x))\n",
    "\n",
    "def kfoldCV(data, shape, nf = \"5\", mode = 'u', verbose = False):\n",
    "    kf = KFold(data.shape[0], n_folds = nf, shuffle=True)\n",
    "\n",
    "    rmse_list = []\n",
    "    print('Performing '+str(nf)+'-foldCV '+ str(mode)+'-i'+' CF...\\n')\n",
    "    cycle = 0\n",
    "    \n",
    "    for train, test in kf:\n",
    "        if verbose: print('Iteration '+str(cycle))\n",
    "        trMat = uMat(data.iloc[train], shape)\n",
    "        teMat = uMat(data.iloc[test], shape)\n",
    "        \n",
    "        prediction = pred(trMat, mode)['pred']\n",
    "        \n",
    "        rmse_cycle = rmse(prediction, teMat)\n",
    "        rmse_list.append(rmse_cycle)\n",
    "        \n",
    "        if verbose: print('  -->'+str(rmse_cycle)+'\\n')\n",
    "        cycle += 1\n",
    "\n",
    "    kfold_rmse = np.mean(rmse_list)\n",
    "    \n",
    "    if verbose: print(str(nf)+'-foldCV rmse: ', str(kfold_rmse))\n",
    "    \n",
    "    return {\"rmse_list\":rmse_list, \"rmse\":kfold_rmse}\n",
    "\n",
    "\n",
    "def train_test_validation(ratings, shape, testSize = 0.2):\n",
    "    from sklearn.cross_validation import train_test_split as tts\n",
    "    trSet, teSet = tts(ratings, test_size = testSize)\n",
    "    trMat, teMat = uMat(trSet, shape), uMat(teSet, shape)\n",
    "\n",
    "    print('User-Item rmse :'+str( rmse(pred(trMat)['pred'], teMat) ) )\n",
    "    print('Item-Item rmse :'+str( rmse(pred(trMat,'i')['pred'], teMat) ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv('./BX-Book-Ratings.csv',\\\n",
    "           header = 0,\n",
    "           names = ['UserID', 'ISBN', 'BookRating'],\n",
    "           encoding = 'ISO-8859-1', \n",
    "           delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "ratings = ratings[ratings['BookRating'] != 0]   \n",
    "ratings = ratings.sample(int(ratings.shape[0]*0.8))\n",
    "\n",
    "URateNum = ratings.groupby('UserID')['BookRating'].count()\n",
    "IRateNum = ratings.groupby('ISBN')['BookRating'].count()\n",
    "\n",
    "Uidx = URateNum[URateNum < 8].index\n",
    "Iidx = IRateNum[IRateNum < 8].index\n",
    "\n",
    "ratings.drop(ratings[ratings['UserID'].isin(Uidx)].index, axis = 0, inplace = True)\n",
    "ratings.drop(ratings[ratings['ISBN'].isin(Iidx)].index, axis = 0, inplace = True)\n",
    "\n",
    "ratings['UserID'] = pd.Categorical(ratings['UserID'])\n",
    "ratings['ISBN'] = pd.Categorical(ratings['ISBN'])\n",
    "\n",
    "ratings['U'] = ratings['UserID'].cat.codes\n",
    "ratings['I'] = ratings['ISBN'].cat.codes\n",
    "\n",
    "\n",
    "shape = (ratings['U'].unique().shape[0], \n",
    "        ratings['I'].unique().shape[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CLUSTERING (to execute only one time)\n",
    "\n",
    "X = uMat(ratings, shape) # utility matrix\n",
    "\n",
    "# Define clustering model, agglomerative clustering with cosine metrics\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from time import time as t\n",
    "\n",
    "CLUSTER_NUM = 2000\n",
    "clMod = AgglomerativeClustering(n_clusters= CLUSTER_NUM, \n",
    "                                affinity='cosine',    # cosine similarity matrix\n",
    "                                linkage = 'average', \n",
    "                                pooling_func = nmean,\n",
    "                               compute_full_tree = False)\n",
    "\n",
    "# Cluster users \n",
    "print('Clustering dataset by user...')\n",
    "start_time = t()\n",
    "clMod.fit(X)    # sort clustering model with users\n",
    "print('Time elapsed: '+str(round(t()-start_time,2))+' sec')\n",
    "\n",
    "ratings.sort_values('U', inplace = True)    # Sort by User \n",
    "labels = pd.Series(clMod.labels_, index = ratings.U.unique())    # cluster labels with User index \n",
    "ratings['UClusterID'] = labels.loc[ratings['U']].values    # column with cluster label\n",
    "\n",
    "# Cluster items\n",
    "print('Clustering dataset by item...')\n",
    "clMod.fit(X.T)    # sort clustering model with items\n",
    "print('Time elapsed: '+str(round(t()-start_time,2))+' sec')\n",
    "\n",
    "ratings.sort_values('I', inplace = True)    # sorte by ISBN\n",
    "labels = pd.Series(clMod.labels_, index = ratings.I.unique())    # clustering labels with ISBN index\n",
    "ratings['IClusterID'] = labels.loc[ratings['I']].values    # column with cluster label \n",
    "\n",
    "# Refresh Rating Table\n",
    "UClusterBR = ratings.groupby('UClusterID')['BookRating'].mean()    # the rating for the cluster is the mean of ratings\n",
    "IClusterBR = ratings.groupby('IClusterID')['BookRating'].mean()\n",
    "\n",
    "ratings['UClusterBR'] = UClusterBR.loc[ratings['UClusterID']].values    # create mean columns\n",
    "ratings['IClusterBR'] = IClusterBR.loc[ratings['IClusterID']].values\n",
    "\n",
    "IClusterBRMeans = ratings.groupby('UClusterID')['IClusterBR'].mean()    # merge Ucluster mean and Icluster to obtain\n",
    "ratings['IClusterBRU'] = IClusterBRMeans.loc[ratings['UClusterID']].values    # the {i,j} rate\n",
    "ratings['BookRatingC'] = (ratings['UClusterBR']+ratings['IClusterBRU'])/2\n",
    "\n",
    "# Save Rating Table\n",
    "ratings.to_csv(\"ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Rating Table\n",
    "clust_rat_col = ['UserID', 'ISBN', 'BookRatingC','UClusterID','IClusterID']\n",
    "ratings_cluster = pd.read_csv('ratings.csv', index_col = False)\n",
    "ratings_cluster = ratings_cluster[clust_rat_col] \n",
    "shape_clust = (ratings_cluster.UClusterID.unique().shape[0], \n",
    "         ratings_cluster.IClusterID.unique().shape[0])    # shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Item rmse :0.268792714629\n",
      "Item-Item rmse :0.896388712476\n"
     ]
    }
   ],
   "source": [
    "# Train/Test validation\n",
    "train_test_validation(ratings_cluster, shape_clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10-foldCV u-i CF...\n",
      "\n",
      "10-fold rmse user-item CF:  0.22\n",
      "Performing 10-foldCV i-i CF...\n",
      "\n",
      "10-fold rmse item-item CF:  0.95\n"
     ]
    }
   ],
   "source": [
    "# kFold Cross Validation\n",
    "n_fold = 10\n",
    "kfoldrmse_user = kfoldCV(ratings_cluster, shape_clust,  n_fold, 'u', verbose = False)\n",
    "print(str(n_fold)+'-fold rmse user-item CF: ', str(round(kfoldrmse_user['rmse'],2)))\n",
    "\n",
    "\n",
    "kfoldrmse_item = kfoldCV(ratings_cluster, shape_clust, n_fold, 'i', verbose = False)\n",
    "print(str(n_fold)+'-fold rmse item-item CF: ', str(round(kfoldrmse_item['rmse'],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ONLINE RECOMMENDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def makeUser(ratings, filename = 'user.txt', books_num = 10):\n",
    "    ISBN_list = ratings['ISBN'].sample(books_num)\n",
    "    with open(filename, 'w') as f:    # prepare book list\n",
    "        for ISBN in ISBN_list[:books_num+1]:\n",
    "            f.write(str(ISBN)+'\\n')\n",
    "\n",
    "\n",
    "def readBooklist(file_path):\n",
    "    df = pd.read_csv(file_path, \n",
    "                     header = None, \n",
    "                     names = ['ISBN'], \n",
    "                    dtype = 'str')\n",
    "    vector = df.values.flatten().tolist()\n",
    "    \n",
    "    return vector\n",
    "\n",
    "def User(vector, ratings, shape):\n",
    "    user_vec = np.zeros(shape[1])\n",
    "    for isbn in vector:\n",
    "        i = (ratings_cluster[ratings_cluster.ISBN == isbn]\n",
    "             ['IClusterID'].unique().tolist())\n",
    "        user_vec[i] = 1\n",
    "    return user_vec.astype(np.int)\n",
    "\n",
    "def predJac(ratings_cluster, shape_clust, cf_mode = 'u'):\n",
    "    prediction = pred(uMat(ratings_cluster, shape_clust), cf_mode='u')['pred']\n",
    "    predMean = round(prediction.mean(), 2)\n",
    "    prediction[prediction <= prediction.mean()-1] = 0\n",
    "    prediction[prediction>prediction.mean()-1] = 1\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "\n",
    "def recommend(ratings_cluster, vector, Y, n_rec = 3, sim_threshold = 0.95):\n",
    "    similarity = recCluster(user_vec, Y)\n",
    "    books = []\n",
    "    sim = similarity[similarity >= sim_threshold]\n",
    "    for clusterID in sim.index:\n",
    "        cluster = ratings_cluster[ratings_cluster['UClusterID'] == clusterID]\n",
    "        if cluster['BookRatingC'].unique().flatten() > 8 :\n",
    "            books.extend(cluster[cluster['BookRating']>8]['ISBN'].tolist())\n",
    "    \n",
    "    books = set(books)                           \n",
    "    m = list(books.intersection(vector))\n",
    "    for i in m: books.discard(i)\n",
    "    books = list(books)\n",
    "    shuffle(books)\n",
    "    return list(books[:n_rec])\n",
    "\n",
    "from sklearn.metrics import jaccard_similarity_score as jaccard\n",
    "\n",
    "def recCluster(user_vec, utility):\n",
    "    similarity = np.zeros(utility.shape[0])\n",
    "    for i in range(utility.shape[0]):\n",
    "        similarity[i] = jaccard(user_vec, utility[i,:])\n",
    "    sim = pd.Series(similarity)\n",
    "    sim.sort_values(ascending = False, inplace = True)\n",
    "    return sim\n",
    "\n",
    "import isbnlib\n",
    "\n",
    "def isbn2title(isbn_list):\n",
    "        titles = []\n",
    "        for isbn in isbn_list:\n",
    "            titles.append(isbnlib.meta(isbn)['Title'])\n",
    "        return titles\n",
    "\n",
    "def titles(user_isbn, rec_isbn):\n",
    "    book_titles = isbn2title(rec_isbn)\n",
    "    read_books = isbn2title(user_isbn)\n",
    "\n",
    "    book_titles = set(book_titles)\n",
    "    common = list(book_titles.intersection(set(read_books)))\n",
    "    for i in common: book_titles.remove(i)\n",
    "\n",
    "    print('You have read:', 20*'-', *read_books, '\\n',sep = '\\n')\n",
    "    print('You could like:',20*'-',*book_titles,sep = '\\n')\n",
    "    return (read_books,book_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Examples\n",
    "\n",
    "# Random\n",
    "makeUser(ratings, books_num=20) # create random user\n",
    "\n",
    "user_file = './user.txt'\n",
    "HPExample = './HPexample.txt'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Read book list in memory\n",
    "\n",
    "# Read from examples\n",
    "example_num = 'HP'\n",
    "example = pd.read_csv('example'+str(example_num)+'.txt', sep='#', header = None)\n",
    "vector = example[0]    # set vector from example\n",
    "\n",
    "\n",
    "#vector = readBooklist(user_file)\n",
    "#vector = readBooklist(HPExample) \n",
    "\n",
    "user_vec = User(vector, ratings_cluster, shape_clust)    # create the user row \n",
    "Y = predJac(ratings_cluster, shape_clust, cf_mode = 'u')    # create 0/1 matrix from User\n",
    "                                                            # Collaborative Filter predictions\n",
    "similarity = recCluster(user_vec, Y) # calculate user row jaccard similarity with user clusters\n",
    "full_rat = pd.read_csv('./ratings.csv', index_col = 0)    # load in memory the full ratings\n",
    "\n",
    "# Find books to recommend\n",
    "books = recommend(full_rat, \n",
    "                  similarity, \n",
    "                  Y,\n",
    "                  n_rec = 5,    # number of books to recommend\n",
    "                  sim_threshold = 0.99)    # cluster similarity threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have read:\n",
      "0525946233    \n",
      "034540288X    \n",
      "0807083054    \n",
      "0316693324    \n",
      "0743203178    \n",
      "0375412824    \n",
      "0440487617    \n",
      "0440184053    \n",
      "0425116840    \n",
      "1573227331    \n",
      "1558746226    \n",
      "0553562738    \n",
      "0373834284    \n",
      "0345413350    \n",
      "0451167317    \n",
      "0842329269    \n",
      "0345426037    \n",
      "2266023039    \n",
      "0671722751    \n",
      "0446356875    \n",
      "We suggest you:\n",
      "0836218655\n",
      "0446364282\n",
      "0345339711\n",
      "0440998050\n",
      "0440904196\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/fede/anaconda/envs/python3/lib/python3.5/site-packages/isbnlib/_metadata.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(isbn, service, cache)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fede/anaconda/envs/python3/lib/python3.5/site-packages/isbnlib/_imcache.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '9780440998051default'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f304b3423097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You have read:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'We suggest you:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtitles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-fbe21bbbb6ef>\u001b[0m in \u001b[0;36mtitles\u001b[0;34m(user_isbn, rec_isbn)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_isbn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_isbn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mbook_titles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misbn2title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_isbn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mread_books\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misbn2title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_isbn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-fbe21bbbb6ef>\u001b[0m in \u001b[0;36misbn2title\u001b[0;34m(isbn_list)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0misbn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0misbn_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mtitles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misbnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misbn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fede/anaconda/envs/python3/lib/python3.5/site-packages/isbnlib/_ext.py\u001b[0m in \u001b[0;36mmeta\u001b[0;34m(isbn, service, cache)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m\"\"\"Get metadata from worldcat.org ('wcat'), Google Books ('goob') , ...\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mservice\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misbn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misbn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fede/anaconda/envs/python3/lib/python3.5/site-packages/isbnlib/_metadata.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(isbn, service, cache)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mraise\u001b[0m  \u001b[0;31m# <-- IMPORTANT: usually the caches don't return error!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misbn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fede/anaconda/envs/python3/lib/python3.5/site-packages/isbnlib/_merge.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(isbn, processor)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mnamed_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wcat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqwcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'goob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqgoob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'openl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqopen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'parallel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misbn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'serial'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misbn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fede/anaconda/envs/python3/lib/python3.5/site-packages/isbnlib/dev/vias.py\u001b[0m in \u001b[0;36mparallel\u001b[0;34m(named_tasks, arg)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHREADS_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fede/anaconda/envs/python3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fede/anaconda/envs/python3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Output ISBN (as original program)\n",
    "\n",
    "print('You have read:', *vector, sep = '\\n')\n",
    "print('We suggest you:',*books, sep = '\\n')\n",
    "titles(vector, books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0                                         1\n",
      "0  9780747560722   Harry Potter And The Chamber Of Secrets\n",
      "1  9780439708180     Harry Potter And The Sorcerer's Stone\n",
      "2  9780439136365  Harry Potter And The Prisoner Of Azkaban\n",
      "3  9780618260300      The Hobbit, Or, There And Back Again\n",
      "           0                                                  1\n",
      "0   60928336                                 Bel Canto: A Novel\n",
      "1   60188731                        The MacGregors: Daniel, Ian\n",
      "2  373483902    Divine secrets of the Ya-Ya Sisterhood: a novel\n",
      "3  590846280                                 A bend in the road\n",
      "4  446611867  The Adventures Of Captain Underpants: An Epic ...\n"
     ]
    }
   ],
   "source": [
    "# INPUT AND ANSWER\n",
    "print(example)\n",
    "print(pd.read_csv('answer'+str(example_num)+'.txt', sep = '#', header = None))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "read_books, book_titles = titles(vector, books)\n",
    "read_books = list(read_books)\n",
    "book_titles = list(book_titles)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "with open('example4.txt', 'w') as f:\n",
    "    for i in range(len(vector)):\n",
    "        f.write(str(vector[i])+'    #'+str(read_books[i])+'\\n')\n",
    "with open('answer4.txt', 'w') as f:\n",
    "    for i in range(len(books)):\n",
    "        f.write(str(list(books)[i])+'    #'+str(book_titles[i])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
